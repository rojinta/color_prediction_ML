---
title: "PPG Paint Colors: Final Project"
subtitle: "Predict the Hold-out Test Set"
author: "Rojin Taheri"
date: "2023-12-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Packages

```{r}
library(tidyverse)
library(caret)
```

## Read Training Data

```{r}
df <- readr::read_csv("paint_project_train_data.csv", col_names = TRUE)
```

```{r}
dfii <- df %>% 
  mutate(y = boot::logit( (response - 0) / (100 - 0) ) ) %>% 
  select(R, G, B, Lightness, Saturation, Hue, y)
```

## Regression Problem  

For the regression problem, I will be using my Model 7 (interaction of the categorical inputs with all main effect and all pairwise interactions of continuous inputs).

```{r}
set.seed(2001)

my_ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
my_metric <- "RMSE"

mod07 <- train(y ~ (Lightness + Saturation) * (R + G + B + Hue)^2, data = dfii, method = "lm", preProcess = c("center", "scale"), metric = my_metric, trControl = my_ctrl)
```

```{r}
mod07
```

## Classification Problem  

```{r}
dfiiiD <- df %>% 
  select(-response) %>% 
  mutate(outcome = ifelse(outcome == 1, 'event', 'non_event'),
         outcome = factor(outcome, levels = c('event', 'non_event')))
```

For the classification problem, I will be using the Random Forest model. The `caret` package can only tune models for one type of metric at a time. This means that we must train and tune a model twice in order to consider the impact of tuning for maximizing Accuracy vs tuning for maximizing ROC AUC. Therefore, we will first set up training and tuning for accuracy and then repeat the process a second time for AUC-ROC.  

```{r}
set.seed(123)

my_ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5, classProbs = TRUE, summaryFunction = twoClassSummary, savePredictions = TRUE)
my_metric <- "ROC"

rf_mod_roc <- train(outcome ~ ., data = dfiiiD, method = "rf", preProcess = c("center", "scale"), trControl = my_ctrl, metric = my_metric)
```

```{r}
rf_mod_roc
```

```{r}
set.seed(1234)

my_ctrl_acc <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
my_metric_acc <- "Accuracy"

rf_mod_acc <- train(outcome ~ ., data = dfiiiD, method = "rf", preProcess = c("center", "scale"), trControl = my_ctrl_acc, metric = my_metric_acc)
```

```{r}
rf_mod_acc
```

## Hold-out Set Predictions  

```{r}
holdout <- readr::read_csv('paint_project_holdout_data.csv', col_names = TRUE)
```

```{r}
holdout %>% head()
```

```{r}
predict(mod07, newdata = holdout) %>% head()
```

```{r}
predict(rf_mod_roc, newdata = holdout) %>% head()
```

```{r}
predict(rf_mod_acc, newdata = holdout) %>% head()
```

```{r}
predict(rf_mod_roc, newdata = holdout, type = 'prob') %>% head()
```

```{r}
predict(rf_mod_acc, newdata = holdout, type = 'prob') %>% head()
```

## Compile Predictions  

```{r}
my_preds <- tibble::tibble(
  y = predict(mod07, newdata = holdout),
  outcome = predict(rf_mod_acc, newdata = holdout)
) %>% 
  bind_cols(
    predict(rf_mod_acc, newdata = holdout, type = 'prob') %>% 
      select(probability = event)
  ) %>% 
  tibble::rowid_to_column('id')
```

```{r}
my_preds %>% head()
```

```{r}
my_preds %>% 
  readr::write_csv('preds_caret.csv', col_names = TRUE)
```

